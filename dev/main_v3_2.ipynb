{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tools.dataset import score_dataset\n",
    "from tools.preprocessing.missing_values import get_missing_raio, delete_columns, impute_missing_values\n",
    "from tools.preprocessing.outliers import delete_outliers, impute_outliers, get_limits\n",
    "from tools.preprocessing.scaling import minmax\n",
    "from tools.engineering.mi import mi_score\n",
    "from tools.engineering.encoding import one_hot\n",
    "from tools.engineering.clustering import kmc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (79023, 76)\n",
      "test shape: (24353, 75)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './data'\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "\n",
    "# train_origin = train.copy()\n",
    "# test_origin = test.copy()\n",
    "\n",
    "print(f'train shape: {train.shape}')\n",
    "print(f'test shape: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_LAT_LON_YEAR_WEEK</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>week_no</th>\n",
       "      <th>SulphurDioxide_SO2_column_number_density</th>\n",
       "      <th>SulphurDioxide_SO2_column_number_density_amf</th>\n",
       "      <th>SulphurDioxide_SO2_slant_column_number_density</th>\n",
       "      <th>SulphurDioxide_cloud_fraction</th>\n",
       "      <th>SulphurDioxide_sensor_azimuth_angle</th>\n",
       "      <th>...</th>\n",
       "      <th>Cloud_cloud_top_height</th>\n",
       "      <th>Cloud_cloud_base_pressure</th>\n",
       "      <th>Cloud_cloud_base_height</th>\n",
       "      <th>Cloud_cloud_optical_depth</th>\n",
       "      <th>Cloud_surface_albedo</th>\n",
       "      <th>Cloud_sensor_azimuth_angle</th>\n",
       "      <th>Cloud_sensor_zenith_angle</th>\n",
       "      <th>Cloud_solar_azimuth_angle</th>\n",
       "      <th>Cloud_solar_zenith_angle</th>\n",
       "      <th>emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_-0.510_29.290_2019_00</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.603019</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.255668</td>\n",
       "      <td>-98.593887</td>\n",
       "      <td>...</td>\n",
       "      <td>3664.436218</td>\n",
       "      <td>61085.809570</td>\n",
       "      <td>2615.120483</td>\n",
       "      <td>15.568533</td>\n",
       "      <td>0.272292</td>\n",
       "      <td>-12.628986</td>\n",
       "      <td>35.632416</td>\n",
       "      <td>-138.786423</td>\n",
       "      <td>30.752140</td>\n",
       "      <td>3.750994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_-0.510_29.290_2019_01</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.728214</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.130988</td>\n",
       "      <td>16.592861</td>\n",
       "      <td>...</td>\n",
       "      <td>3651.190311</td>\n",
       "      <td>66969.478735</td>\n",
       "      <td>3174.572424</td>\n",
       "      <td>8.690601</td>\n",
       "      <td>0.256830</td>\n",
       "      <td>30.359375</td>\n",
       "      <td>39.557633</td>\n",
       "      <td>-145.183930</td>\n",
       "      <td>27.251779</td>\n",
       "      <td>4.025176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_-0.510_29.290_2019_02</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.748199</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.110018</td>\n",
       "      <td>72.795837</td>\n",
       "      <td>...</td>\n",
       "      <td>4216.986492</td>\n",
       "      <td>60068.894448</td>\n",
       "      <td>3516.282669</td>\n",
       "      <td>21.103410</td>\n",
       "      <td>0.251101</td>\n",
       "      <td>15.377883</td>\n",
       "      <td>30.401823</td>\n",
       "      <td>-142.519545</td>\n",
       "      <td>26.193296</td>\n",
       "      <td>4.231381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_-0.510_29.290_2019_03</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5228.507736</td>\n",
       "      <td>51064.547339</td>\n",
       "      <td>4180.973322</td>\n",
       "      <td>15.386899</td>\n",
       "      <td>0.262043</td>\n",
       "      <td>-11.293399</td>\n",
       "      <td>24.380357</td>\n",
       "      <td>-132.665828</td>\n",
       "      <td>28.829155</td>\n",
       "      <td>4.305286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_-0.510_29.290_2019_04</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>29.29</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>0.676296</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.121164</td>\n",
       "      <td>4.121269</td>\n",
       "      <td>...</td>\n",
       "      <td>3980.598120</td>\n",
       "      <td>63751.125781</td>\n",
       "      <td>3355.710107</td>\n",
       "      <td>8.114694</td>\n",
       "      <td>0.235847</td>\n",
       "      <td>38.532263</td>\n",
       "      <td>37.392979</td>\n",
       "      <td>-141.509805</td>\n",
       "      <td>22.204612</td>\n",
       "      <td>4.347317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID_LAT_LON_YEAR_WEEK  latitude  longitude  year  week_no  \\\n",
       "0  ID_-0.510_29.290_2019_00     -0.51      29.29  2019        0   \n",
       "1  ID_-0.510_29.290_2019_01     -0.51      29.29  2019        1   \n",
       "2  ID_-0.510_29.290_2019_02     -0.51      29.29  2019        2   \n",
       "3  ID_-0.510_29.290_2019_03     -0.51      29.29  2019        3   \n",
       "4  ID_-0.510_29.290_2019_04     -0.51      29.29  2019        4   \n",
       "\n",
       "   SulphurDioxide_SO2_column_number_density  \\\n",
       "0                                 -0.000108   \n",
       "1                                  0.000021   \n",
       "2                                  0.000514   \n",
       "3                                       NaN   \n",
       "4                                 -0.000079   \n",
       "\n",
       "   SulphurDioxide_SO2_column_number_density_amf  \\\n",
       "0                                      0.603019   \n",
       "1                                      0.728214   \n",
       "2                                      0.748199   \n",
       "3                                           NaN   \n",
       "4                                      0.676296   \n",
       "\n",
       "   SulphurDioxide_SO2_slant_column_number_density  \\\n",
       "0                                       -0.000065   \n",
       "1                                        0.000014   \n",
       "2                                        0.000385   \n",
       "3                                             NaN   \n",
       "4                                       -0.000048   \n",
       "\n",
       "   SulphurDioxide_cloud_fraction  SulphurDioxide_sensor_azimuth_angle  ...  \\\n",
       "0                       0.255668                           -98.593887  ...   \n",
       "1                       0.130988                            16.592861  ...   \n",
       "2                       0.110018                            72.795837  ...   \n",
       "3                            NaN                                  NaN  ...   \n",
       "4                       0.121164                             4.121269  ...   \n",
       "\n",
       "   Cloud_cloud_top_height  Cloud_cloud_base_pressure  Cloud_cloud_base_height  \\\n",
       "0             3664.436218               61085.809570              2615.120483   \n",
       "1             3651.190311               66969.478735              3174.572424   \n",
       "2             4216.986492               60068.894448              3516.282669   \n",
       "3             5228.507736               51064.547339              4180.973322   \n",
       "4             3980.598120               63751.125781              3355.710107   \n",
       "\n",
       "   Cloud_cloud_optical_depth  Cloud_surface_albedo  \\\n",
       "0                  15.568533              0.272292   \n",
       "1                   8.690601              0.256830   \n",
       "2                  21.103410              0.251101   \n",
       "3                  15.386899              0.262043   \n",
       "4                   8.114694              0.235847   \n",
       "\n",
       "   Cloud_sensor_azimuth_angle  Cloud_sensor_zenith_angle  \\\n",
       "0                  -12.628986                  35.632416   \n",
       "1                   30.359375                  39.557633   \n",
       "2                   15.377883                  30.401823   \n",
       "3                  -11.293399                  24.380357   \n",
       "4                   38.532263                  37.392979   \n",
       "\n",
       "   Cloud_solar_azimuth_angle  Cloud_solar_zenith_angle  emission  \n",
       "0                -138.786423                 30.752140  3.750994  \n",
       "1                -145.183930                 27.251779  4.025176  \n",
       "2                -142.519545                 26.193296  4.231381  \n",
       "3                -132.665828                 28.829155  4.305286  \n",
       "4                -141.509805                 22.204612  4.347317  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 일부 확인\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop(['ID_LAT_LON_YEAR_WEEK'], axis=1, inplace=True)\n",
    "# test.drop(['ID_LAT_LON_YEAR_WEEK'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 결측값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삭제하지 않을 칼럼\n",
    "protected_columns = ['latitude', 'longitude', 'week_no', 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값 비율이 높은 칼럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제된 칼럼 개수: 7\n"
     ]
    }
   ],
   "source": [
    "train_deleted, deleted_columns = delete_columns(train, 0.3, target='emission')\n",
    "\n",
    "print(f'삭제된 칼럼 개수: {len(deleted_columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에도 적용\n",
    "test_deleted = test.drop(deleted_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결측값 제거 결과\n",
    "# data_list = [['train', train], ['train_deleted', train_deleted]]\n",
    "# results = []\n",
    "\n",
    "# for name, data in data_list:\n",
    "#     score = score_dataset(data, 'emission')\n",
    "#     results.append([name, score])\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "칼럼을 삭제한 데이터셋의 스코어가 더 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 이상적인 결측값 대체법 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods = ['mean', 'linear', 'fill']\n",
    "# results = []\n",
    "\n",
    "# for method in methods:\n",
    "#     train_imputed, _ = impute_missing_values(train_deleted, method)\n",
    "#     score = score_dataset(train_imputed, 'emission')\n",
    "#     results.append([method, score])\n",
    "#     print(f'method \"{method}\" 계산 완료')\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_method = sorted(results, key=lambda x: x[1])[0]\n",
    "# print(f'best method: {best_method}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_imputed, _ = impute_missing_values(train_deleted, best_method[0])\n",
    "# test_imputed, _ = impute_missing_values(test_deleted, best_method[0])\n",
    "\n",
    "train_imputed, _ = impute_missing_values(train_deleted, 'fill')\n",
    "test_imputed, _ = impute_missing_values(test_deleted, 'fill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_now = train_imputed\n",
    "test_now = test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_dataset(train_now, 'emission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 칼럼 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "month 및 covid 칼럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_now['date'] = pd.to_datetime('2021' + train_now['week_no'].astype(str) + '0', format='%Y%W%w')\n",
    "train_now['month_no'] = train_now['date'].dt.month\n",
    "train_now.drop(columns=['date'], inplace=True)\n",
    "\n",
    "train_now['covid'] = (train_now.year == 2020) & (train_now.month_no > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_now['date'] = pd.to_datetime('2021' + test_now['week_no'].astype(str) + '0', format='%Y%W%w')\n",
    "test_now['month_no'] = test_now['date'].dt.month\n",
    "test_now.drop(columns=['date'], inplace=True)\n",
    "\n",
    "test_now['covid'] = (test_now.year == 2020) & (test_now.month_no > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loven\\dev\\kaggle_competition\\carbon\\carbon\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_now, encoder = one_hot(train_now, 'covid')\n",
    "test_now, _ = one_hot(test_now, 'covid', encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_now.rename(columns={0: 'covid_false', 1: 'covid_true'}, inplace=True)\n",
    "test_now.rename(columns={0: 'covid_false', 1: 'covid_true'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_columns.extend(['covid_False', 'covid_True', 'month_no'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "season 칼럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON = {\n",
    "    'summer': [12, 1, 2],\n",
    "    'fall': [3, 4, 5],\n",
    "    'winter': [6, 7, 8],\n",
    "    'spring': [9, 10, 11],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_season(x, season):\n",
    "    if x in season['summer']:\n",
    "        return 'summer'\n",
    "    elif x in season['fall']:\n",
    "        return 'fall'\n",
    "    elif x in season['winter']:\n",
    "        return 'winter'\n",
    "    elif x in season['spring']:\n",
    "        return 'spring'\n",
    "    else:\n",
    "        raise Exception('unknown week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season\n",
      "summer    20874\n",
      "fall      19383\n",
      "winter    19383\n",
      "spring    19383\n",
      "Name: count, dtype: int64 season\n",
      "fall      6461\n",
      "winter    6461\n",
      "spring    6461\n",
      "summer    4970\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_now['season'] = train_now['month_no'].apply(insert_season, args=[SEASON])\n",
    "\n",
    "test_now['season'] = test_now['month_no'].apply(insert_season, args=[SEASON])\n",
    "\n",
    "print(train_now['season'].value_counts(), test_now['season'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "계절별 데이터셋 따로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summer = train_now.loc[train_now['season'] == 'summer']\n",
    "train_fall = train_now.loc[train_now['season'] == 'fall']\n",
    "train_winter = train_now.loc[train_now['season'] == 'winter']\n",
    "train_spring = train_now.loc[train_now['season'] == 'spring']\n",
    "\n",
    "test_summer = test_now.loc[test_now['season'] == 'summer']\n",
    "test_fall = test_now.loc[test_now['season'] == 'fall']\n",
    "test_winter = test_now.loc[test_now['season'] == 'winter']\n",
    "test_spring = test_now.loc[test_now['season'] == 'spring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = [train_summer, train_fall, train_winter, train_spring]\n",
    "test_sets = [test_summer, test_fall, test_winter, test_spring]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_sets)):\n",
    "    train_sets[i] = train_sets[i].drop('season', axis=1)\n",
    "\n",
    "for i in range(len(test_sets)):\n",
    "    test_sets[i] = test_sets[i].drop('season', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Selection(by Mutual Information, Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train의 칼럼 개수: 9\n",
      "1 train의 칼럼 개수: 9\n",
      "2 train의 칼럼 개수: 9\n",
      "3 train의 칼럼 개수: 9\n"
     ]
    }
   ],
   "source": [
    "selected_columns = []\n",
    "\n",
    "for idx, train in enumerate(train_sets):\n",
    "    df, columns, _ = mi_score(train, 'emission', 0.4, corr=True, corr_threshold=0.4, protected=protected_columns)\n",
    "    columns.remove('emission')\n",
    "    selected_columns.append(columns)\n",
    "    train_sets[idx] = df\n",
    "    print(f'{idx} train의 칼럼 개수: {len(train_sets[idx].columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.652852165161999\n",
      "8.735763951839694\n",
      "8.427803324867021\n",
      "8.95630990981607\n"
     ]
    }
   ],
   "source": [
    "for train in train_sets:\n",
    "    print(score_dataset(train, 'emission'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, test in enumerate(test_sets):\n",
    "    test_sets[idx] = test.loc[:, selected_columns[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = ['latitude', 'longitude', 'emission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elbow method is excecuting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loven\\dev\\kaggle_competition\\carbon\\carbon\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\loven\\dev\\kaggle_competition\\carbon\\carbon\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elbow method is excecuting\n",
      "The elbow method is excecuting\n",
      "The elbow method is excecuting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loven\\dev\\kaggle_competition\\carbon\\carbon\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\loven\\dev\\kaggle_competition\\carbon\\carbon\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# clusters = []\n",
    "# encoders = []\n",
    "\n",
    "# for idx, train in enumerate(train_sets):\n",
    "#     df_km = train.groupby(by=['latitude', 'longitude'], as_index=False)['emission'].mean()\n",
    "#     df_cluster, cluster, _, n_clusters = kmc(df_km, features, n_clusters=5, elbow=True, encoding=False)\n",
    "#     train_sets[idx] = train.merge(df_cluster[['latitude', 'longitude', 'cluster']], on=['latitude', 'longitude'])\n",
    "    \n",
    "#     train_sets[idx], encoder = one_hot(train_sets[idx], 'cluster')\n",
    "    \n",
    "#     encoders.append(encoder)\n",
    "#     clusters.append(df_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, test in enumerate(test_sets):\n",
    "#     # df_km = test.groupby(by=['latitude', 'longitude'], as_index=False)['emission'].mean()\n",
    "#     # df_cluster, _, _, _ = kmc(test, features, cluster=clusters[idx], encoding=False)\n",
    "#     test_sets[idx] = test.merge(clusters[idx][['latitude', 'longitude', 'cluster']], on=['latitude', 'longitude'])\n",
    "#     test_sets[idx], _ = one_hot(test_sets[idx], 'cluster', encoders[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 최종 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summer', 'fall', 'winter', 'spring']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_order = list(SEASON.keys())\n",
    "season_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = []\n",
    "\n",
    "for idx, train in enumerate(train_sets):\n",
    "    col = list(map(str, list(train.columns)))\n",
    "    train.columns = col\n",
    "    col.sort()\n",
    "    train_reordered = train[col]\n",
    "    col.remove('emission')\n",
    "    train_columns.append(col)\n",
    "    data_name = os.path.join(DATA_PATH, '0808/train_{}_3.csv'.format(season_order[idx]))\n",
    "    train_reordered.to_csv(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, test in enumerate(test_sets):\n",
    "    col = list(map(str, list(test.columns)))\n",
    "    test.columns = col\n",
    "    test_reordered = test[train_columns[idx]]\n",
    "    data_name = os.path.join(DATA_PATH, '0808/test_{}_3.csv'.format(season_order[idx]))\n",
    "    test_reordered.to_csv(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carbon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
